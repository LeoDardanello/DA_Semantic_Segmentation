{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoDardanello/DA_Semantic_Segmentation/blob/main/Semantic_DA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um0XeVbimTpW",
        "outputId": "fb2e6c77-6491-4c6b-906a-d145022e9517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpT5jzhinC8f",
        "outputId": "b57d4821-1f50-4426-f6b9-9c375adf6389"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=\"7z x '/content/drive/MyDrive/AML/Cityscapes.zip' -o'./'\", returncode=2, stdout=b'\\n7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\\np7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\\n\\nScanning the drive for archives:\\n1 file, 4973983436 bytes (4744 MiB)\\n\\nExtracting archive: /content/drive/MyDrive/AML/Cityscapes.zip\\n--\\nPath = /content/drive/MyDrive/AML/Cityscapes.zip\\nType = zip\\nERRORS:\\nHeaders Error\\nPhysical Size = 4973983436\\n64-bit = +\\n\\n\\n\\nArchives with Errors: 1\\n\\nOpen Errors: 1\\n\\n', stderr=b'\\nERRORS:\\nHeaders Error\\n\\n')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "percorso_zip = \"/content/drive/MyDrive/AML/Cityscapes.zip\"\n",
        "\n",
        "percorso_destinazione = \"./\"\n",
        "\n",
        "comando_7zip = f\"7z x '{percorso_zip}' -o'{percorso_destinazione}'\"\n",
        "\n",
        "subprocess.run(comando_7zip, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX2md0PHIjYo",
        "outputId": "a3a1326a-5a8c-4191-9e63-7e7e0aa30e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'DA_Semantic_Segmentation'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 94 (delta 49), reused 42 (delta 18), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (94/94), 521.29 KiB | 11.33 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/LeoDardanello/DA_Semantic_Segmentation.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG-PkH4ZRRcP"
      },
      "outputs": [],
      "source": [
        "# os.chdir(\"DA_Semantic_Segmentation/\")\n",
        "# !ls\n",
        "# !git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXAEPOl7yKyo"
      },
      "source": [
        "**TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OLyUV_fySMB",
        "outputId": "c4d713fb-84c8-4b81-af84-15701e9c5f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLzEawkgDxbh",
        "outputId": "6aaf84f9-de1a-44fb-eea4-b10d46fa7863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "use pretrain model /content/drive/MyDrive/STDCNet813M_73.91.tar\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DA_Semantic_Segmentation/train.py\", line 264, in <module>\n",
            "    main()\n",
            "  File \"/content/DA_Semantic_Segmentation/train.py\", line 241, in main\n",
            "    model = BiSeNet(backbone=args.backbone, n_classes=n_classes, pretrain_model=args.pretrain_path, use_conv_last=args.use_conv_last, training_model=args.training_path)\n",
            "  File \"/content/DA_Semantic_Segmentation/model/model_stages.py\", line 246, in __init__\n",
            "    self.cp = ContextPath(backbone, pretrain_model,training_model=training_model, use_conv_last=use_conv_last)\n",
            "  File \"/content/DA_Semantic_Segmentation/model/model_stages.py\", line 104, in __init__\n",
            "    self.backbone = STDCNet813(pretrain_model=pretrain_model, use_conv_last=use_conv_last, training_model=training_model)\n",
            "  File \"/content/DA_Semantic_Segmentation/model/stdcnet.py\", line 149, in __init__\n",
            "    self.init_weight(pretrain_model)\n",
            "  File \"/content/DA_Semantic_Segmentation/model/stdcnet.py\", line 166, in init_weight\n",
            "    state_dict = torch.load(pretrain_model)[\"state_dict\"]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1028, in load\n",
            "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1256, in _legacy_load\n",
            "    result = unpickler.load()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1193, in persistent_load\n",
            "    wrap_storage=restore_location(obj, location),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 381, in default_restore_location\n",
            "    result = fn(storage, location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 274, in _cuda_deserialize\n",
            "    device = validate_cuda_device(location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 258, in validate_cuda_device\n",
            "    raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
            "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
          ]
        }
      ],
      "source": [
        "!python3 \"/content/DA_Semantic_Segmentation/train.py\" --num_epochs 50 --num_workers 2 --checkpoint_step 5 --validation_step 10 --save_model_path \"/content/DA_Semantic_Segmentation/out\" --pretrain_path \"/content/drive/MyDrive/STDCNet813M_73.91.tar\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
