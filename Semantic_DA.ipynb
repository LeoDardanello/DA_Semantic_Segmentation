{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoDardanello/DA_Semantic_Segmentation/blob/main/Semantic_DA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um0XeVbimTpW",
        "outputId": "02b278e9-a021-4192-d36c-8963fb3c7684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpT5jzhinC8f",
        "outputId": "b57d4821-1f50-4426-f6b9-9c375adf6389"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=\"7z x '/content/drive/MyDrive/AML/Cityscapes.zip' -o'./'\", returncode=2, stdout=b'\\n7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\\np7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\\n\\nScanning the drive for archives:\\n1 file, 4973983436 bytes (4744 MiB)\\n\\nExtracting archive: /content/drive/MyDrive/AML/Cityscapes.zip\\n--\\nPath = /content/drive/MyDrive/AML/Cityscapes.zip\\nType = zip\\nERRORS:\\nHeaders Error\\nPhysical Size = 4973983436\\n64-bit = +\\n\\n\\n\\nArchives with Errors: 1\\n\\nOpen Errors: 1\\n\\n', stderr=b'\\nERRORS:\\nHeaders Error\\n\\n')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "percorso_zip = \"/content/drive/MyDrive/AML/Cityscapes.zip\"\n",
        "\n",
        "percorso_destinazione = \"./\"\n",
        "\n",
        "comando_7zip = f\"7z x '{percorso_zip}' -o'{percorso_destinazione}'\"\n",
        "\n",
        "subprocess.run(comando_7zip, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX2md0PHIjYo",
        "outputId": "9e423ecd-dbf7-485f-f744-00652f8b379a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DA_Semantic_Segmentation'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 148 (delta 80), reused 58 (delta 26), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (148/148), 534.76 KiB | 5.00 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"/content/DA_Semantic_Segmentation\"):\n",
        "  !rm -rf \"/content/DA_Semantic_Segmentation\"\n",
        "!git clone \"https://github.com/LeoDardanello/DA_Semantic_Segmentation.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG-PkH4ZRRcP"
      },
      "outputs": [],
      "source": [
        "# os.chdir(\"DA_Semantic_Segmentation/\")\n",
        "# !ls\n",
        "# !git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXAEPOl7yKyo"
      },
      "source": [
        "**TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OLyUV_fySMB",
        "outputId": "354df397-9ab9-43d3-8daf-6088f7d128c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLzEawkgDxbh",
        "outputId": "6aaf84f9-de1a-44fb-eea4-b10d46fa7863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "use pretrain model /content/drive/MyDrive/STDCNet813M_73.91.tar\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DA_Semantic_Segmentation/train.py\", line 264, in <module>\n",
            "    main()\n",
            "  File \"/content/DA_Semantic_Segmentation/train.py\", line 241, in main\n",
            "    model = BiSeNet(backbone=args.backbone, n_classes=n_classes, pretrain_model=args.pretrain_path, use_conv_last=args.use_conv_last, training_model=args.training_path)\n",
            "  File \"/content/DA_Semantic_Segmentation/model/model_stages.py\", line 246, in __init__\n",
            "    self.cp = ContextPath(backbone, pretrain_model,training_model=training_model, use_conv_last=use_conv_last)\n",
            "  File \"/content/DA_Semantic_Segmentation/model/model_stages.py\", line 104, in __init__\n",
            "    self.backbone = STDCNet813(pretrain_model=pretrain_model, use_conv_last=use_conv_last, training_model=training_model)\n",
            "  File \"/content/DA_Semantic_Segmentation/model/stdcnet.py\", line 149, in __init__\n",
            "    self.init_weight(pretrain_model)\n",
            "  File \"/content/DA_Semantic_Segmentation/model/stdcnet.py\", line 166, in init_weight\n",
            "    state_dict = torch.load(pretrain_model)[\"state_dict\"]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1028, in load\n",
            "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1256, in _legacy_load\n",
            "    result = unpickler.load()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1193, in persistent_load\n",
            "    wrap_storage=restore_location(obj, location),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 381, in default_restore_location\n",
            "    result = fn(storage, location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 274, in _cuda_deserialize\n",
            "    device = validate_cuda_device(location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 258, in validate_cuda_device\n",
            "    raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
            "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
          ]
        }
      ],
      "source": [
        "!python3 \"/content/DA_Semantic_Segmentation/train.py\" --num_epochs 50 --num_workers 2 --checkpoint_step 5 --validation_step 10 --save_model_path \"/content/DA_Semantic_Segmentation/out\" --pretrain_path \"/content/drive/MyDrive/STDCNet813M_73.91.tar\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GTA 5 TEST\n"
      ],
      "metadata": {
        "id": "2arO58xOaLLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "\n",
        "transform=ToPILImage()\n",
        "image,label=GATTO[0]\n",
        "image=transform(image)\n",
        "\n",
        "\n",
        "# if not torch.all(label>=0 & label<19 | label==255):\n",
        "#   print(\"ERRORE\")\n",
        "\n",
        "plt.imshow(np.array(image))\n",
        "plt.show()\n",
        "plt.imshow(label.numpy(),cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sICIfNTfaKFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "percorso_zip = \"/content/drive/MyDrive/AML/GTA5.zip\"\n",
        "\n",
        "percorso_destinazione = \"./\"\n",
        "\n",
        "comando_7zip = f\"7z x '{percorso_zip}' -o'{percorso_destinazione}'\"\n",
        "\n",
        "subprocess.run(comando_7zip, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)"
      ],
      "metadata": {
        "id": "jfztS1rcp7Vw",
        "outputId": "ce5db17c-486b-49aa-870d-42a6faf22112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=\"7z x '/content/drive/MyDrive/AML/GTA5.zip' -o'./'\", returncode=2, stdout=b'\\n7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\\np7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\\n\\nScanning the drive for archives:\\n1 file, 6215145033 bytes (5928 MiB)\\n\\nExtracting archive: /content/drive/MyDrive/AML/GTA5.zip\\n--\\nPath = /content/drive/MyDrive/AML/GTA5.zip\\nType = zip\\nERRORS:\\nHeaders Error\\nPhysical Size = 6215145033\\n64-bit = +\\n\\n\\n\\nArchives with Errors: 1\\n\\nOpen Errors: 1\\n\\n', stderr=b'\\nERRORS:\\nHeaders Error\\n\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/DA_Semantic_Segmentation/train.py\" --num_epochs 50 --num_workers 2 --dataset_train \"GTA5\" --checkpoint_step 5 --validation_step 10 --save_model_path \"/content/DA_Semantic_Segmentation/out\" --pretrain_path \"/content/drive/MyDrive/STDCNet813M_73.91.tar\""
      ],
      "metadata": {
        "id": "2vFWG2hQp67p",
        "outputId": "3cc64b06-7bd2-4f68-cc94-950310965e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use pretrain model /content/drive/MyDrive/STDCNet813M_73.91.tar\n",
            "epoch 0, lr 0.010000: 100% 1250/1250 [02:06<00:00,  9.92it/s, loss=2.565052]\n",
            "loss for train : 2.976872\n",
            "epoch 1, lr 0.009820: 100% 1250/1250 [02:06<00:00,  9.91it/s, loss=2.086204]\n",
            "loss for train : 2.375303\n",
            "epoch 2, lr 0.009639: 100% 1250/1250 [02:03<00:00, 10.08it/s, loss=1.928802]\n",
            "loss for train : 2.155220\n",
            "epoch 3, lr 0.009458: 100% 1250/1250 [02:00<00:00, 10.35it/s, loss=2.080985]\n",
            "loss for train : 2.294462\n",
            "epoch 4, lr 0.009277: 100% 1250/1250 [02:02<00:00, 10.24it/s, loss=1.929485]\n",
            "loss for train : 2.143681\n",
            "epoch 5, lr 0.009095: 100% 1250/1250 [02:01<00:00, 10.30it/s, loss=1.775202]\n",
            "loss for train : 2.018796\n",
            "epoch 6, lr 0.008913:  30% 380/1250 [00:37<01:46,  8.20it/s, loss=5.853404]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/GTA5/TrainID\""
      ],
      "metadata": {
        "id": "Y7JwoX8JtWuy"
      },
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}